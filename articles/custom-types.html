<!DOCTYPE html>
<!-- Generated by pkgdown: do not edit by hand --><html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="description" content="torchexport">
<title>Custom types • torchexport</title>
<script src="../deps/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="../deps/bootstrap-5.2.2/bootstrap.min.css" rel="stylesheet">
<script src="../deps/bootstrap-5.2.2/bootstrap.bundle.min.js"></script><!-- Font Awesome icons --><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css" integrity="sha256-mmgLkCYLUQbXn0B1SRqzHar6dCnv9oZFPEC1g1cwlkk=" crossorigin="anonymous">
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/v4-shims.min.css" integrity="sha256-wZjR52fzng1pJHwx4aV2AO3yyTOXrcDW7jBpJtTwVxw=" crossorigin="anonymous">
<!-- bootstrap-toc --><script src="https://cdn.jsdelivr.net/gh/afeld/bootstrap-toc@v1.0.1/dist/bootstrap-toc.min.js" integrity="sha256-4veVQbu7//Lk5TSmc7YV48MxtMy98e26cf5MrgZYnwo=" crossorigin="anonymous"></script><!-- headroom.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/headroom.min.js" integrity="sha256-AsUX4SJE1+yuDu5+mAVzJbuYNPHj/WroHuZ8Ir/CkE0=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/headroom/0.11.0/jQuery.headroom.min.js" integrity="sha256-ZX/yNShbjqsohH1k95liqY9Gd8uOiE1S4vZc+9KQ1K4=" crossorigin="anonymous"></script><!-- clipboard.js --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><!-- search --><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- pkgdown --><script src="../pkgdown.js"></script><meta property="og:title" content="Custom types">
<meta property="og:description" content="torchexport">
<!-- mathjax --><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js" integrity="sha256-nvJJv9wWKEm88qvoQl9ekL2J+k/RWIsaSScxxlsrv8k=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/config/TeX-AMS-MML_HTMLorMML.js" integrity="sha256-84DKXVJXs0/F8OTMzX4UR909+jtl4G7SPypPavF+GfA=" crossorigin="anonymous"></script><!--[if lt IE 9]>
<script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
<script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
<![endif]-->
</head>
<body>
    <a href="#main" class="visually-hidden-focusable">Skip to contents</a>
    

    <nav class="navbar fixed-top navbar-light navbar-expand-lg bg-light"><div class="container">
    
    <a class="navbar-brand me-2" href="../index.html">torchexport</a>

    <small class="nav-text text-muted me-auto" data-bs-toggle="tooltip" data-bs-placement="bottom" title="">0.0.1.9000</small>

    
    <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbar" aria-controls="navbar" aria-expanded="false" aria-label="Toggle navigation">
      <span class="navbar-toggler-icon"></span>
    </button>

    <div id="navbar" class="collapse navbar-collapse ms-3">
      <ul class="navbar-nav me-auto">
<li class="nav-item">
  <a class="nav-link" href="../reference/index.html">Reference</a>
</li>
<li class="active nav-item dropdown">
  <a href="#" class="nav-link dropdown-toggle" data-bs-toggle="dropdown" role="button" aria-expanded="false" aria-haspopup="true" id="dropdown-articles">Articles</a>
  <div class="dropdown-menu" aria-labelledby="dropdown-articles">
    <a class="dropdown-item" href="../articles/behind_the_scenes.html">torchexport: Behind the scenes</a>
    <a class="dropdown-item" href="../articles/custom-types.html">Custom types</a>
  </div>
</li>
      </ul>
<form class="form-inline my-2 my-lg-0" role="search">
        <input type="search" class="form-control me-sm-2" aria-label="Toggle navigation" name="search-input" data-search-index="../search.json" id="search-input" placeholder="Search for" autocomplete="off">
</form>

      <ul class="navbar-nav">
<li class="nav-item">
  <a class="external-link nav-link" href="https://github.com/mlverse/torchexport/" aria-label="github">
    <span class="fab fa fab fa-github fa-lg"></span>
     
  </a>
</li>
      </ul>
</div>

    
  </div>
</nav><div class="container template-article">




<div class="row">
  <main id="main" class="col-md-9"><div class="page-header">
      <img src="" class="logo" alt=""><h1>Custom types</h1>
            
      
      <small class="dont-index">Source: <a href="https://github.com/mlverse/torchexport/blob/HEAD/vignettes/articles/custom-types.Rmd" class="external-link"><code>vignettes/articles/custom-types.Rmd</code></a></small>
      <div class="d-none name"><code>custom-types.Rmd</code></div>
    </div>

    
    
<div class="sourceCode" id="cb1"><pre class="downlit sourceCode r">
<code class="sourceCode R"><span><span class="kw"><a href="https://rdrr.io/r/base/library.html" class="external-link">library</a></span><span class="op">(</span><span class="va"><a href="https://github.com/mlverse/torchexport" class="external-link">torchexport</a></span><span class="op">)</span></span></code></pre></div>
<p>When extending torch with C++, you might want your C++ function to
return types that are not defined in <a href="https://github.com/mlverse/torch/blob/93b250ae48911f572d5477e8f52b19c40a5da86c/inst/include/torch_types.h#L659-L763" class="external-link">torch.h</a>,
or ones where no automatic casting from and to <code>raw</code> pointers
has yet been implemented in <a href="https://github.com/mlverse/torch/blob/93b250ae48911f572d5477e8f52b19c40a5da86c/lantern/include/lantern/types.h#L50-L113" class="external-link">lantern/types.h</a>.
<code>torchexport</code> can be extended to support custom types defined
in user packages, provided that you implement all the necessary
casting:</p>
<ul>
<li>
<code>frow_raw</code> and <code>make_raw</code> : On the
<code>csrc</code> side, you must specify how your type is to be
converted to a <code>void*</code> pointer, as well as how to convert
from <code>void*</code> to your custom type.</li>
<li>
<code>Rcpp</code> type: On the Rcpp side ,you need to implement the
casting between <code>void*</code> and a custom Rcpp type that can
manage the memory pointed by this <code>void*</code>.</li>
<li>Rcpp type to <code>SEXP</code>: if you ever return this type to R
(as opposed to only using it in Rcpp) you need to implement casting from
the Rcpp custom type to a <code>SEXP</code>.</li>
<li>
<code>SEXP</code> to Rcpp type: if you use this type as an argument
on the R side, you must implement the casting from <code>SEXP</code> to
your custom type.</li>
</ul>
<div class="section level2">
<h2 id="example">Example<a class="anchor" aria-label="anchor" href="#example"></a>
</h2>
<p>In this example we will implement the <code>tensor_pair</code> type,
an alias for
<code>std::tuple&lt;torch::Tensor, torch::Tensor&gt;</code>. This type
is not implemented in <code>torch</code>, thus we need to implement it
ourselves. In fact, this type was needed in the <a href="https://github.com/mlverse/torchsparse" class="external-link">torchsparse</a> package;
that’s why the names of the files will sometimes start with
<code>torchsparse_</code>.</p>
<div class="section level3">
<h3 id="the-csrc-side">The <code>csrc</code> side<a class="anchor" aria-label="anchor" href="#the-csrc-side"></a>
</h3>
<p>First we will create a file called <code>torchparse_types.h</code> in
the <code>csrc/include/torchsparse</code> directory. This file will
contain the declaration of your custom type and the declarations for the
functions that allows casting this type to and from <code>void*</code>
pointers.</p>
<p>For example, it can look like this:</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;torch/torch.h&gt;</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a><span class="co">// declares the alias, but could also be a `class CustomType`.</span></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="kw">using</span> tensor_pair <span class="op">=</span> <span class="bu">std::</span>tuple<span class="op">&lt;</span>torch<span class="op">::</span>Tensor<span class="op">,</span>torch<span class="op">::</span>Tensor<span class="op">&gt;;</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co">// In this namespace we declare the function that creates a `void*`</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co">// from an instance of your type. This `void*` pointer must own all</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co">// its memory.</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="kw">namespace</span> make_raw <span class="op">{</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>  <span class="dt">void</span><span class="op">*</span> TensorPair <span class="op">(</span><span class="at">const</span> tensor_pair<span class="op">&amp;</span> x<span class="op">);</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a><span class="co">// In this namespace we declare a function that takes a void* pointer and</span></span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a><span class="co">// returns a reference to your type. It's a good idea to return by </span></span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a><span class="co">// reference.</span></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="kw">namespace</span> from_raw <span class="op">{</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>  tensor_pair<span class="op">&amp;</span> TensorPair <span class="op">(</span><span class="dt">void</span><span class="op">*</span> x<span class="op">);</span></span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Now that we declared the type and it’s casting functions, we will
implement these functions. The name of the file doesn’t matter here, but
it’s nice to use <code>torchsparse_types.cpp</code>. This file lives in
<code>csrc/src</code>. Don’t forget to add it to the
<code>CMakeLists.txt</code> file so it also gets compiled.</p>
<p>The implementation of <code>make_raw::TensorPair</code> and
<code>from_raw::TensorPair</code> look like this:</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;torch/torch.h&gt;</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">"torchsparse/torchsparse_types.h"</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;torchsparse/sparse.h&gt;</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;lantern/types.h&gt;</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="kw">namespace</span> make_raw <span class="op">{</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a><span class="co">// This is mostly the same as:</span></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="co">// return (void*) new tensor_pair(x); </span></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="co">// but in a fancy C++ way.</span></span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span><span class="op">*</span> TensorPair <span class="op">(</span><span class="at">const</span> tensor_pair<span class="op">&amp;</span> x<span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> make_ptr<span class="op">&lt;</span>tensor_pair<span class="op">&gt;(</span>x<span class="op">);</span></span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a><span class="co">// This simply tells the compiler to consider that `void*` is a pointer to</span></span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a><span class="co">// `tensor_pair` and then returns this reference.</span></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a><span class="kw">namespace</span> from_raw <span class="op">{</span></span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>tensor_pair<span class="op">&amp;</span> TensorPair <span class="op">(</span><span class="dt">void</span><span class="op">*</span> x<span class="op">)</span> <span class="op">{</span></span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="op">*</span><span class="kw">reinterpret_cast</span><span class="op">&lt;</span>tensor_pair<span class="op">*&gt;(</span>x<span class="op">);</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co">// ---- there's more.</span></span></code></pre></div>
<p>Additionally in this file we will implement functions that will allow
us to free the memory pointed by this pointer, as well as tools to help
us cast this type to something that we can return to R.</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="co">// Takes a void* pointer and deletes the memory it points to.</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span class="co">// First need to cast to the correct type.</span></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co">// [[torch::export]]</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span> delete_tensor_pair<span class="op">(</span><span class="dt">void</span><span class="op">*</span> x<span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  <span class="kw">delete</span> <span class="kw">reinterpret_cast</span><span class="op">&lt;</span>tensor_pair<span class="op">*&gt;(</span>x<span class="op">);</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span class="co">// Extract a single Tensor from this type. This will allow us to</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span class="co">// convert this type into a list of tensors to pass to R.</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a><span class="co">// [[torch::export]]</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>torch<span class="op">::</span>Tensor tensor_pair_get_first<span class="op">(</span>tensor_pair x<span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="bu">std::</span>get<span class="op">&lt;</span><span class="dv">0</span><span class="op">&gt;(</span>x<span class="op">);</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co">// [[torch::export]]</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>torch<span class="op">::</span>Tensor tensor_pair_get_second<span class="op">(</span>tensor_pair x<span class="op">)</span> <span class="op">{</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> <span class="bu">std::</span>get<span class="op">&lt;</span><span class="dv">1</span><span class="op">&gt;(</span>x<span class="op">);</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>We are done with the type implementation on the <code>csrc</code>
side. We can now implement a function that uses this type. For
example:</p>
<div class="sourceCode" id="cb5"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="co">// [[torch::export(register_types=c("tensor_pair", "TensorPair", "void*", "torchsparse::tensor_pair"))]]</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>tensor_pair sparse_relabel<span class="op">(</span>torch<span class="op">::</span>Tensor col<span class="op">,</span> torch<span class="op">::</span>Tensor idx<span class="op">)</span> <span class="op">{</span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> relabel<span class="op">(</span>col<span class="op">,</span> idx<span class="op">);</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>Note the arguments in the <code>// [[torch::export]]</code> special
comment. Here we are telling <code>torchexport</code> what to generate.
Namely, on encountering the type
<strong><code>tensor_pair</code></strong> (first argument), it
should:</p>
<ul>
<li>Use <code>make_raw::TensorPair</code> and
<code>from_raw::TensorPair</code> to cast between <code>void*</code> and
<code>tensor_pair</code>. (<code>TensorPair</code> is the second
argument.)</li>
<li>Use <code>void*</code> as the C type. In general it will always be
<code>void*</code> here, unless you can cast to another C type and still
re-create the object. (<code>void*</code> is the third argument.)</li>
<li>Use <code>torchsparse::tensor_pair</code> as the Rcpp type.
(<code>torchsparse::tensor_pair</code> is the third argument.) This we
haven’t implemented yet; it’ll be our next step.</li>
</ul>
<p><strong>Note</strong>: You only need to register the type once, for a
single function that uses it. If we want to export other functions that
return <code>tensor_pair</code> we won’t need to register the type again
in the <code>[[torch::export]]</code> comment.</p>
<p>We can now <code>cmake --build . --target install --parallel 8</code>
to compile the <code>csrc</code> library, and everything should go
fine.</p>
</div>
<div class="section level3">
<h3 id="the-rcpp-side">The <code>Rcpp</code> side<a class="anchor" aria-label="anchor" href="#the-rcpp-side"></a>
</h3>
<p>Now, on to the Rcpp side. We need to implement the custom Rcpp type
that will hold the <code>void*</code> pointer returned from the
<code>csrc</code> side, take care of the corresponding memory, and cast
to <code>SEXP</code> when needed.</p>
<p>First we declare this type in
<code>src/torchsparse_types.h</code>:</p>
<div class="sourceCode" id="cb6"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#pragma once</span></span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;torch.h&gt;</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a><span class="kw">namespace</span> torchsparse <span class="op">{</span></span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a><span class="kw">class</span> tensor_pair <span class="op">{</span></span>
<span id="cb6-7"><a href="#cb6-7" aria-hidden="true" tabindex="-1"></a><span class="kw">public</span><span class="op">:</span></span>
<span id="cb6-8"><a href="#cb6-8" aria-hidden="true" tabindex="-1"></a>  <span class="co">// this is the slot to hold the void*</span></span>
<span id="cb6-9"><a href="#cb6-9" aria-hidden="true" tabindex="-1"></a>  <span class="bu">std::</span>shared_ptr<span class="op">&lt;</span><span class="dt">void</span><span class="op">&gt;</span> ptr<span class="op">;</span></span>
<span id="cb6-10"><a href="#cb6-10" aria-hidden="true" tabindex="-1"></a>  <span class="co">// the constructor from a void*</span></span>
<span id="cb6-11"><a href="#cb6-11" aria-hidden="true" tabindex="-1"></a>  tensor_pair <span class="op">(</span><span class="dt">void</span><span class="op">*</span> x<span class="op">);</span></span>
<span id="cb6-12"><a href="#cb6-12" aria-hidden="true" tabindex="-1"></a>  <span class="co">// casting operator Rcpp-&gt;SEXP</span></span>
<span id="cb6-13"><a href="#cb6-13" aria-hidden="true" tabindex="-1"></a>  <span class="kw">operator</span> SEXP <span class="op">()</span> <span class="at">const</span><span class="op">;</span></span>
<span id="cb6-14"><a href="#cb6-14" aria-hidden="true" tabindex="-1"></a>  <span class="co">// returns the void* from the type.</span></span>
<span id="cb6-15"><a href="#cb6-15" aria-hidden="true" tabindex="-1"></a>  <span class="dt">void</span><span class="op">*</span> get <span class="op">();</span></span>
<span id="cb6-16"><a href="#cb6-16" aria-hidden="true" tabindex="-1"></a><span class="op">};</span></span>
<span id="cb6-17"><a href="#cb6-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb6-18"><a href="#cb6-18" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>The type having been declared, we can now implement its member
functions in <code>src/torchsparse_types.cpp</code>:</p>
<div class="sourceCode" id="cb7"><pre class="sourceCode cpp"><code class="sourceCode cpp"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">&lt;Rcpp.h&gt;</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">"torchsparse_types.h"</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span class="pp">#include </span><span class="im">"exports.h"</span></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a><span class="kw">namespace</span> torchsparse <span class="op">{</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span class="dt">void</span><span class="op">*</span> tensor_pair<span class="op">::</span>get<span class="op">()</span> <span class="op">{</span></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> ptr<span class="op">.</span>get<span class="op">();</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a><span class="co">// Creates a list of two torch::Tensor's from this object.</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>tensor_pair<span class="op">::</span><span class="kw">operator</span> SEXP <span class="op">()</span> <span class="at">const</span> <span class="op">{</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>  Rcpp<span class="op">::</span>List out<span class="op">;</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>  out<span class="op">.</span>push_back<span class="op">(</span>rcpp_tensor_pair_get_first<span class="op">(*</span><span class="kw">this</span><span class="op">));</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>  out<span class="op">.</span>push_back<span class="op">(</span>rcpp_tensor_pair_get_second<span class="op">(*</span><span class="kw">this</span><span class="op">));</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>  <span class="cf">return</span> out<span class="op">;</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a><span class="co">// initialize the `ptr` slot and **very important** register the custom</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a><span class="co">// deleter `rcpp_delete_tensor_pair` that will free the pointer's memory</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a><span class="co">// once `ptr` is gone (and hence once the `torchsparse::tensor_pair` instance</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a><span class="co">// is gone).</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>tensor_pair<span class="op">::</span>tensor_pair <span class="op">(</span><span class="dt">void</span><span class="op">*</span> x<span class="op">)</span> <span class="op">:</span> ptr<span class="op">(</span>x<span class="op">,</span> rcpp_delete_tensor_pair<span class="op">)</span> <span class="op">{};</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a><span class="op">}</span></span></code></pre></div>
<p>You should now be able to <code>devtools::load_all()</code> and call
<code>rcpp_sparse_relabel()</code>. This function will return a list
with two <code>torch</code> Tensors.</p>
<p>In this case, we don’t need to provide functionality for casting from
a <code>SEXP</code> to the Rcpp type. If we had to, we’d have to
implement the <code>tensor_pair::tensor_pair (SEXP x)</code>
constructor, and probably have a function similar to
<code>rcpp_tensor_pair_get_first</code>, but doing things the other way
around: i.e., taking two <code>torch</code> Tensors and returning a
<code>tensor_pair</code>.</p>
<p>Finally, this tutorial is more like a set of notes (from when I was
implementing that functionality in <code>torchsparse</code>) than a
“tutorial”. Please open an issue if something is not clear, and we will
be very happy to help!</p>
</div>
</div>
  </main><aside class="col-md-3"><nav id="toc"><h2>On this page</h2>
    </nav></aside>
</div>



    <footer><div class="pkgdown-footer-left">
  <p></p>
<p>Developed by Daniel Falbel.</p>
</div>

<div class="pkgdown-footer-right">
  <p></p>
<p>Site built with <a href="https://pkgdown.r-lib.org/" class="external-link">pkgdown</a> 2.0.7.</p>
</div>

    </footer>
</div>

  

  

  </body>
</html>
